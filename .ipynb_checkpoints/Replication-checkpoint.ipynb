{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replicating Research from Spring\n",
    "\n",
    "by Joshua Delgadillo, Lauren Craft, Adam Perlin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Update 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our team chose to research the novel Coronavirus. In 2020 SARS-CoV-2 began spreading across the world and there has been an widespread effort to understand the virus and research ways to combat it. Bioinformatics takes the forefront in understanding the genetic makeup of the virus and its mutations. Our contributions to the research into understanding SARS-CoV-2 include tracing similarities between SARS-CoV-2 and two viruses that have previously spread. These two viruses are SARS-CoV-1 and MERS-CoV. Much of our research and data collection involved taking sequences of these three viruses and examining the relationships between them in order to extract data to determine similarities and differences between them.\n",
    "\n",
    "The data used in our research came from the National Center for Biotechnology Information (NCBI). The NCBI contains a vast amount of bioinformatic related databases including several databases which contain virus specific DNA sequences. The database that we focused our data extraction on was the NCBIâ€©",
    "Nucleotide Database. From this database we were able to collect several sequence samples to use in our research."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working on:\n",
    " 1. How to Jupyter Notebooks\n",
    " 2. Relevant Githubs\n",
    " 3. New (but similiar??) data\n",
    " 4. The Alternative Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relevant GitHubs\n",
    "\n",
    "Analysis using k-mer composition\n",
    "https://anderson-github-classroom.github.io/csc-448-project/eagranof/\n",
    "\n",
    "Even more analysis using k-mer composition\n",
    "https://anderson-github-classroom.github.io/csc-448-project/skurdogh/ \n",
    "\n",
    "Vitulgin Experimentation\n",
    "https://anderson-github-classroom.github.io/csc-448-project/cilg/\n",
    "\n",
    "The Levenshtein distance experiment\n",
    "https://anderson-github-classroom.github.io/csc-448-project/awengel/ \n",
    "\n",
    "Mutation Rate Comparison and Spike Proteins\n",
    "https://anderson-github-classroom.github.io/csc-448-project/pamidi/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Sample Data\n",
    "\n",
    "The [NCBI Nucleotide Database] was used to get data last time: \"This database provides multiple SARS-Cov-2 sequences, but in an effort to focus our analysis, we select an arbitrarily random subset of sequences to analyze\". I have a simple thought: we choose another arbitrarily random subset of sequences to analyze, which will put us at arbitrary<sup>2</sup> (aka where you want to be)\n",
    "\n",
    "According to the [report from Spring], 677 sequences were used. Therefore, we should use 678 to literally 1-up them. We can compare our dataset to theirs to ensure everything looks right.\n",
    "\n",
    "[NCBI Nucleotide Database]: https://www.ncbi.nlm.nih.gov/nuccore\n",
    "[report from Spring]: https://nbviewer.jupyter.org/github/anderson-github-classroom/csc-448-project/blob/master/students/enewcome/supplemental-table/table.ipynb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Alternative Algorithm\n",
    "\n",
    "Needleman-Wunsch Algorithm or the Smith-Waterman Algorithm can be used to compare the similiarity of two viruses. The former was used in the Spring, so we will use the Smith-Waterman Algorithm.\n",
    "\n",
    "From what I can tell (and I'm not smart...so grains of salt), NWA fins the optimal global alignment and SWA find the best local alignment, which means: \"something\". I need to look back at my sequence alignment notes, but here are my current thoughts: If we run the SWA algorithm and the local alignment is enormous, then the strands of RNA are very similiar.\n",
    "\n",
    "Some pseduo code:\n",
    "\n",
    "~~~\n",
    "\n",
    "Given: String s1 with length m , String s2 with length n\n",
    "\n",
    "    // initialize matrix, M\n",
    "    \n",
    "    // score cells in matrix\n",
    "    for i=1 to m\n",
    "        for j=1 to n\n",
    "        \n",
    "            // initialization: max is 0\n",
    "            max = 0 \n",
    "            \n",
    "            // first comparison: west cell (deletion)\n",
    "            score = M[i][j-1] + gapScore\n",
    "            if( score > max )\n",
    "                max = score\n",
    "            \n",
    "            // second comparison: north cell (insertion)\n",
    "            score = M[i-1][j] + gapScore\n",
    "            if( score > max )\n",
    "                max = score\n",
    "            \n",
    "            // last comparison: north-west cell (alignment)\n",
    "            base1 = s1[j-1]\n",
    "            base2 = s2[i-1]\n",
    "            \n",
    "            if( base1 == base2 )              // match\n",
    "                alignmentScore = matchScore\n",
    "            else                              // mismatch\n",
    "                alignmentScore = mismatchScore\n",
    "            \n",
    "            score = M[i-1][j-1] + alignmentScore\n",
    "            if( score > max )\n",
    "                max = score\n",
    "            \n",
    "            // finished all comparisons\n",
    "            M[i][j] = max\n",
    "    \n",
    "    // return completed matrix\n",
    "    return M\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stray Thoughts\n",
    "\n",
    "1. There were doubts about Virulign, can't we just use Blast?\n",
    "2. Need to verify my beliefs with bio.\n",
    "3. Shoudl we use only the most recent data.\n",
    "4. SWA is hopefully mostly done after our lab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Update 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feedback\n",
    "\n",
    "Professor Anderson asked us to consider if we should or shouldn't implement the algorithm by hand. The primary benefit would be our familiarization with the code and control over parameters, but we give up precious time. \n",
    "\n",
    "We decided to try using BLAST after all, but <b>is it actually what we need?</b> Names can be very misleading."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proving we can use BLAST\n",
    "\n",
    "Proof by obvious: \n",
    "~~~\n",
    "\n",
    "lemma 1: Smith-Waterman is a \"local aligment\" algorithm.\n",
    "\n",
    "B.L.A.S.T. stands for basic \"local alignment\" search tool.\n",
    "\n",
    "Done.\n",
    "~~~\n",
    "\n",
    "From the [BLAST website]: \"The Basic Local Alignment Search Tool (BLAST) finds regions of local similarity between sequences. The program compares nucleotide or protein sequences to sequence databases and calculates the statistical significance of matches.\"\n",
    "\n",
    "In our research, we found out BLAST actually uses a faster (but less precise) version of Smith-Waterman. A heuristic is used to eliminate sequences that are not likely to be a good local alignment. The shortcut was necessary because the algorithm is too slow when ran with large datasets. source: [The NCBI Handbook]\n",
    "\n",
    "[BLAST website]: https://blast.ncbi.nlm.nih.gov/Blast.cgi\n",
    "[The NCBI Handbook]: https://www.unmc.edu/bsbc/docs/NCBI_blast.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Data\n",
    "\n",
    "We pulled data from the [NCBI Virus] database. There are strands of SARS-CoV-1, SARS-CoV-2, and MERS-CoV in .fasta files. We read about how the alogrithm struggles with large datasets, so we reconsidered using 678 sequences (becuase crossing 678 sequences with 678 sequences is enormous). We decided to scale it back a lot becuase logic supersedes sarcasm. Instead, we are each going to run blast on one of each sequence and then we'll cross reference our results to ensure we all did it correctly. Furthermore, we're sequence aligning the proteins instead of nucleotides to lessen the amount of work BLAST needs to do. From there, we can run BLAST on as many sequences as we want. \n",
    "\n",
    "[NCBI Virus]: https://www.ncbi.nlm.nih.gov/labs/virus/vssi/#/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function \"print_fasta\" does exactly what you'd expect: prints a .fasta file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "import pandas as pd \n",
    "  \n",
    "def print_fasta(virus_name, file_name):\n",
    "    # initialize list of lists \n",
    "    data = []\n",
    "\n",
    "    fasta_sequences = SeqIO.parse(open(file_name),'fasta')\n",
    "    with open(file_name) as out_file:\n",
    "        for fasta in fasta_sequences:\n",
    "            name, sequence = fasta.id, str(fasta.seq)\n",
    "            data.append([name, sequence])\n",
    "\n",
    "    # Create the pandas DataFrame \n",
    "    df = pd.DataFrame(data, columns = [virus_name, 'sequence']) \n",
    "\n",
    "    # print dataframe. \n",
    "    print(df) \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can print out our three sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SARS-CoV-1                                           sequence\n",
      "0  ATO98191.1  MESLVLGVNEKTHVQLSLPVLQVRDVLVRGFGDSVEEALSEAREHL...\n",
      "   SARS-CoV-1                                           sequence\n",
      "0  AGT21121.1  MESLVLGVNEKTHVQLSLPVLQVRDVLVRGFGDSVEEALSEAREHL...\n",
      "    SARS-CoV-1                                           sequence\n",
      "0   AEA10518.1  MFIFLLFLTLTSGSDLDRCTTFDDVQAPNYTQHTSSMRGVYYPDEI...\n",
      "1   AEA10517.1  MESLVLGVNEKTHVQLSLPVLQVRDVLVRGFGDSVEEALSEAREHL...\n",
      "2   AEA10516.1  MESLVLGVNEKTHVQLSLPVLQVRDVLVRGFGDSVEEALSEAREHL...\n",
      "3   AEA10528.1  MSDNGPQSNQRSAPRITFGGPTDSTDNNQNGGRNGARPKQRRPQGL...\n",
      "4   AEA10522.1  MADNGTITVEKLKQLLEQWNLVIGFLFLAWIMLLQFAYSNRNRFLY...\n",
      "5   AEA10527.1  MCLKILVRYNTRGNTYSTAWLCALGKVLPFHRWHTMVQTCTPNVTI...\n",
      "6   AEA10526.1            MKLLIVLTCISLCSCICTVVQRCASNKPHVLEDPCKVQH\n",
      "7   AEA10524.1  MKIILFLTLIVFTSCELYHYQECVRGTTVLLKEPCPSGTYEGNSPF...\n",
      "8   AEA10523.1  MFHLVDFQVTIAEILIIIMRTFRIAIWNLDVIISSIVRQLFKPLTK...\n",
      "9   AEA10520.1  MMPTTLFAGTHITMTTVYHITVSQIQLSLLKVTAFQHQNSKKTTKL...\n",
      "10  AEA10519.1  MDLFMRFFTLGSITAQPVKIDNASPASTVHATATIPLQASLPFGWL...\n",
      "11  AEA10529.1  MDPNQTNVVPPALHLVDPQIQLTITRMEDAMGQGQNSADPKVYPII...\n",
      "12  AEA10525.1       MNELTLIDFYLCFLAFLLFLVLIMLIIFWFSLEIQDLEEPCTKV\n",
      "13  AEA10530.1  MLPPCYNFLKEQHCQKASTQREAEAAVKPLLAPHHVVAVIQEIQLL...\n",
      "14  AEA10521.1  MYSFVSEETGTLIVNSVLLFLAFVVFLLVTLAILTALRLCAYCCNI...\n",
      "\n",
      "   SARS-CoV-2                                           sequence\n",
      "0  QOP81761.1  MESLVPGFNEKTHVQLSLPVLQVRDVLVRGFGDSVEEVLSEARQHL...\n",
      "   SARS-CoV-2                                           sequence\n",
      "0  QOR64135.1  MESLVPGFNEKTHVXXXXXXXXXXXXXXXXXXXXXXXXXSEARQHL...\n",
      "    SARS-CoV-2                                           sequence\n",
      "0   QMT93566.1  MESLVPGFNEKTHVQLSLPVLQVRDVLVRGFGDSVEEVLSEARQHL...\n",
      "1   QMT93567.1  MESLVPGFNEKTHVQLSLPVLQVRDVLVRGFGDSVEEVLSEARQHL...\n",
      "2   QMT93568.1  MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...\n",
      "3   QMT93569.1  MDLFMRIFTIGTVTLKQGEIKDATPSDFVRATATIPIQASLPFGWL...\n",
      "4   QMT93570.1  MYSFVSEETGTLIVNSVLLFLAFVVFLLVTLAILTALRLCAYCCNI...\n",
      "5   QMT93571.1  MADSNGTITVEELKKLLEQWNLVIGFLFLTWICLLQFAYANRNRFL...\n",
      "6   QMT93572.1  MFHLVDFQVTIAEILLIIMRTFKVSIWNLDYIINLIIKNLSKSLTE...\n",
      "7   QMT93573.1  MKIILFLALITLATCELYHYQECVRGTTVLLKEPCSSGTYEGNSPF...\n",
      "8   QMT93574.1        MIELSLIDFYLCFLAFLLFLVLIMLIIFWFSLELQDHNETCHA\n",
      "9   QMT93575.1  MKFLVFLGIITTVAAFHQECSLQSCTQHQPYVVDDPCPIHFYSKWY...\n",
      "10  QMT93576.1  MSDNGPQNQRNAPRITFGGPSDSTGSNQNGERSGARSKQRRPQGLP...\n",
      "11  QMT93577.1             MGYINVFAFPFTIYSLLLCRMNSRNYIAQVDVVNFNLT\n",
      "\n",
      "     MERS-CoV                                           sequence\n",
      "0  AVV62535.1  MSSVAGVVAQGARNRYRAALNNEKRPDHVSLTVPCCGTGDLAEHLS...\n",
      "     MERS-CoV                                           sequence\n",
      "0  AUM60013.1  MSSVAGVATQGARSMYRAALNSEKRPDHVSRTVPCCGTGDLVSKLS...\n",
      "      MERS-CoV                                           sequence\n",
      "0   AID50417.1  MSFVAGVTAQGARGTYRAALNSEKHQDHVSLTVPLCGSGNLVEKLS...\n",
      "1   AID50418.1  MIHSVFLLMFLLTPTESYVDVGPDSVKSACIEVDIQQTFFDKTWPR...\n",
      "2   AID50419.1  MRVQRPPTLLLVFSLSLLVTAFSKPLYVPEHCQNYSGCMLRACIKT...\n",
      "3   AID50420.1  MDYVSLLNQIWQKYLNSPYTTCLYIPKPTAKYTPLVGTSLHPVLWN...\n",
      "4   AID50421.1  MEESLMDVPSTSGTQVYSRKARKRSHSPTKKLRYVKRRFSLLRPED...\n",
      "5   AID50422.1  MAFSASLFKPVQLVPVSPAFHRIESTDSIVFTYIPASGYVAALAVN...\n",
      "6   AID50423.1  MLPFVQERIGLFIVNFFIFTVVCAITLLVCMAFLTATRLCVQCMTG...\n",
      "7   AID50424.1  MSNMTQLTEAQIIAIIKDWNFAWSLIFLLITIVLQYGYPSRSMTVY...\n",
      "8   AID50425.1  MASPAAPRAVSFADNNDITNTNLSRGRGRNPKPRAAPNNTVSWYTG...\n",
      "9   AID50426.1  MPIPPLRKMLGIGGDRTEKLIPGMELSNWLPGGISTTLELDPKQHS...\n",
      "10  AID50427.1  MSFVAGVTAQGARGTYRAALNSEKHQDHVSLTVPLCGSGNLVEKLS...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "data_dir = \"test_data\"\n",
    "sample_types = [\n",
    "    \"SARS-CoV-1\",\n",
    "    \"SARS-CoV-2\",\n",
    "    \"MERS-CoV\"\n",
    "]\n",
    "\n",
    "for sample_type in sample_types:\n",
    "    for sample in glob(data_dir+\"/{}*.fasta\".format(sample_type)):\n",
    "        print_fasta(sample_type, sample)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLASTing Seqeunces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to create a blast database for our three datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Building a new DB, current time: 11/06/2020 02:24:22\n",
      "New DB name:   /home/jupyter-aperlin/448/test_data/SARS-CoV-1-ATO98191.fasta\n",
      "New DB title:  test_data/SARS-CoV-1-ATO98191.fasta\n",
      "Sequence type: Protein\n",
      "Deleted existing Protein BLAST database named /home/jupyter-aperlin/448/test_data/SARS-CoV-1-ATO98191.fasta\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 1 sequences in 0.000207901 seconds.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Building a new DB, current time: 11/06/2020 02:24:22\n",
      "New DB name:   /home/jupyter-aperlin/448/test_data/SARS-CoV-2-QOP81761.fasta\n",
      "New DB title:  test_data/SARS-CoV-2-QOP81761.fasta\n",
      "Sequence type: Protein\n",
      "Deleted existing Protein BLAST database named /home/jupyter-aperlin/448/test_data/SARS-CoV-2-QOP81761.fasta\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 1 sequences in 0.000200987 seconds.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Building a new DB, current time: 11/06/2020 02:24:22\n",
      "New DB name:   /home/jupyter-aperlin/448/test_data/MERS-CoV-AUM60013.fasta\n",
      "New DB title:  test_data/MERS-CoV-AUM60013.fasta\n",
      "Sequence type: Protein\n",
      "Deleted existing Protein BLAST database named /home/jupyter-aperlin/448/test_data/MERS-CoV-AUM60013.fasta\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 1 sequences in 0.000200033 seconds.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "/usr/local/ncbi-blast-2.10.1+/bin/makeblastdb -in test_data/SARS-CoV-1-ATO98191.fasta -dbtype prot\n",
    "/usr/local/ncbi-blast-2.10.1+/bin/makeblastdb -in test_data/SARS-CoV-2-QOP81761.fasta -dbtype prot\n",
    "/usr/local/ncbi-blast-2.10.1+/bin/makeblastdb -in test_data/MERS-CoV-AUM60013.fasta -dbtype prot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We did it! Where are our diplomas? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we run blast on every pair (the number of threads was bumped up to the max becuase why not?):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "/usr/local/ncbi-blast-2.10.1+/bin/blastp -query ./test_data/SARS-CoV-1-ATO98191.fasta -db ./test_data/SARS-CoV-2-QOP81761.fasta -evalue 1e-6 -num_threads 16 -out ./test_data/blast_S1_S2.txt\n",
    "/usr/local/ncbi-blast-2.10.1+/bin/blastp -query ./test_data/SARS-CoV-1-ATO98191.fasta -db ./test_data/MERS-CoV-AUM60013.fasta -evalue 1e-6 -num_threads 16 -out ./test_data/blast_S1_M.txt\n",
    "/usr/local/ncbi-blast-2.10.1+/bin/blastp -query ./test_data/SARS-CoV-2-QOP81761.fasta -db ./test_data/MERS-CoV-AUM60013.fasta -evalue 1e-6 -num_threads 16 -out ./test_data/blast_S2_M.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out BLAST result of SARS-CoV-1 and SARS-CoV-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Score = 12938 bits (33578),  Expect = 0.0, Method: Compositional matrix adjust.\r\n",
      " Identities = 6126/7101 (86%), Positives = 6599/7101 (93%), Gaps = 33/7101 (0%)\r\n"
     ]
    }
   ],
   "source": [
    "!grep -A1 \"Score = \" ./test_data/blast_S1_S2.txt | head -2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out BLAST result of SARS-CoV-1 and MERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Score = 6032 bits (15650),  Expect = 0.0, Method: Compositional matrix adjust.\r\n",
      " Identities = 3061/6037 (51%), Positives = 4050/6037 (67%), Gaps = 195/6037 (3%)\r\n"
     ]
    }
   ],
   "source": [
    "!grep -A1 \"Score = \" ./test_data/blast_S1_M.txt | head -2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out BLAST result of SARS-CoV-2 and MERS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Score = 6061 bits (15723),  Expect = 0.0, Method: Compositional matrix adjust.\r\n",
      " Identities = 3055/5946 (51%), Positives = 4030/5946 (68%), Gaps = 177/5946 (3%)\r\n"
     ]
    }
   ],
   "source": [
    "!grep -A1 \"Score = \" ./test_data/blast_S2_M.txt | head -2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true
   },
   "source": [
    "Clean up test_data directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm ./test_data/*.fasta.*\n",
    "!rm ./test_data/*.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Update 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results From Last Week\n",
    "\n",
    "Isn't it great when a plan comes together? We idenpently ran BLAST on our sequences and our results were similiar. Furthermore, our average was already close to what was found in the Spring, so now we're going to sequence more strands to get better results. We asked Bio for what was a good number of strands for each virus, and they advised us to use ten, so that's what we're going to do.\n",
    "\n",
    "The following process is the same as the one above (same source for data, still using BLAST), just on a much greater scale. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a blast database for our three datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Building a new DB, current time: 11/13/2020 19:10:17\n",
      "New DB name:   /home/jupyter-aperlin/448/data/SARS-CoV-1-Sequences.fasta\n",
      "New DB title:  data/SARS-CoV-1-Sequences.fasta\n",
      "Sequence type: Protein\n",
      "Deleted existing Protein BLAST database named /home/jupyter-aperlin/448/data/SARS-CoV-1-Sequences.fasta\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 10 sequences in 0.000945091 seconds.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Building a new DB, current time: 11/13/2020 19:10:17\n",
      "New DB name:   /home/jupyter-aperlin/448/data/SARS-CoV-2-Sequences.fasta\n",
      "New DB title:  data/SARS-CoV-2-Sequences.fasta\n",
      "Sequence type: Protein\n",
      "Deleted existing Protein BLAST database named /home/jupyter-aperlin/448/data/SARS-CoV-2-Sequences.fasta\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 10 sequences in 0.000940084 seconds.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Building a new DB, current time: 11/13/2020 19:10:17\n",
      "New DB name:   /home/jupyter-aperlin/448/data/MERS-CoV-Sequences.fasta\n",
      "New DB title:  data/MERS-CoV-Sequences.fasta\n",
      "Sequence type: Protein\n",
      "Deleted existing Protein BLAST database named /home/jupyter-aperlin/448/data/MERS-CoV-Sequences.fasta\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 10 sequences in 0.000908852 seconds.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "/usr/local/ncbi-blast-2.10.1+/bin/makeblastdb -in data/SARS-CoV-1-Sequences.fasta -dbtype prot\n",
    "/usr/local/ncbi-blast-2.10.1+/bin/makeblastdb -in data/SARS-CoV-2-Sequences.fasta -dbtype prot\n",
    "/usr/local/ncbi-blast-2.10.1+/bin/makeblastdb -in data/MERS-CoV-Sequences.fasta -dbtype prot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run blast on every pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "/usr/local/ncbi-blast-2.10.1+/bin/blastp -query ./data/SARS-CoV-1-Sequences.fasta -db ./data/SARS-CoV-2-Sequences.fasta -evalue 1e-6 -num_threads 16 -out ./data/blast_S1_S2.txt\n",
    "/usr/local/ncbi-blast-2.10.1+/bin/blastp -query ./data/SARS-CoV-1-Sequences.fasta -db ./data/MERS-CoV-Sequences.fasta -evalue 1e-6 -num_threads 16 -out ./data/blast_S1_M.txt\n",
    "/usr/local/ncbi-blast-2.10.1+/bin/blastp -query ./data/SARS-CoV-2-Sequences.fasta -db ./data/MERS-CoV-Sequences.fasta -evalue 1e-6 -num_threads 16 -out ./data/blast_S2_M.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to pass this information on to Bio because CS majors can only read binary. We plan to auotmate the process of finding the average result, but we don't have the time quite yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out results of comparisons (top alignment score in every output file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SARS-CoV-1 x SARS-CoV-2\n",
      " Score = 7494 bits (19445),  Expect = 0.0, Method: Compositional matrix adjust.\n",
      " Identities = 3545/4412 (80%), Positives = 3946/4412 (89%), Gaps = 37/4412 (1%)\n",
      "SARS-CoV-1 x MERS-CoV\n",
      " Score = 2214 bits (5738),  Expect = 0.0, Method: Compositional matrix adjust.\n",
      " Identities = 1258/3271 (38%), Positives = 1874/3271 (57%), Gaps = 169/3271 (5%)\n",
      "SARS-CoV-2 x MERS-CoV\n",
      " Score = 6061 bits (15723),  Expect = 0.0, Method: Compositional matrix adjust.\n",
      " Identities = 3055/5946 (51%), Positives = 4030/5946 (68%), Gaps = 177/5946 (3%)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "echo \"SARS-CoV-1 x SARS-CoV-2\"\n",
    "grep -A1 -m1 \"Score =\" ./data/blast_S1_S2.txt | head -2\n",
    "echo \"SARS-CoV-1 x MERS-CoV\"\n",
    "grep -A1 -m1 \"Score =\" ./data/blast_S1_M.txt | head -2\n",
    "echo \"SARS-CoV-2 x MERS-CoV\"\n",
    "grep -A1 -m1 \"Score =\" ./data/blast_S2_M.txt | head -2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ./data/blast_S2_M.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm ./data/*.fasta.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sequence(filename):\n",
    "    file = open(\"./mutation_data/\" +filename)\n",
    "    sequence = \"\"\n",
    "    count = 0\n",
    "    \n",
    "    for line in file:\n",
    "        if count != 0:\n",
    "            sequence += line.replace('\\n', '')\n",
    "        count += 1\n",
    "        \n",
    "    return sequence\n",
    "        \n",
    "    \n",
    "def find_mutations():\n",
    "    out_file_1 = open(\"./mutation_data/results.txt\", \"w\")\n",
    "    out_file_2 = open(\"./mutation_data/differences.txt\", \"w\")\n",
    "    reference_genome = get_sequence(\"reference_seq.fasta\")\n",
    "    mutation_filename = \"seq_00.fasta\"\n",
    "    \n",
    "    mutations = []\n",
    "    \n",
    "    for i in range(1, 31):\n",
    "        temp = mutation_filename[:4] + f'{i:02}' + mutation_filename[6:]\n",
    "        mutation = get_sequence(temp)\n",
    "        mutations.append(mutation)\n",
    "    \n",
    "    for i in range(len(mutations)):\n",
    "        mutation = mutations[i]\n",
    "        \n",
    "        if mutation[23402] == 'G':\n",
    "            out_file_1.write(str(i + 1) + \" - \" + mutation[23402] + \"\\n\")\n",
    "    \n",
    "    for i in range(len(mutations)):\n",
    "        out_file_2.write(str(i) + \" - differences\")\n",
    "        mutation = mutations[i]\n",
    "        differences = \"\"\n",
    "        min_len = min(len(reference_genome), len(mutation))\n",
    "        \n",
    "        \n",
    "        for j in range(min_len):\n",
    "            if(reference_genome[j] != mutation[j]):\n",
    "                differences += reference_genome[j]\n",
    "            else:\n",
    "                differences += \"-\"\n",
    "                \n",
    "        out_file_2.write(reference_genome)\n",
    "        out_file_2.write(differences)\n",
    "    \n",
    "find_mutations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 - G\n",
      "21 - G\n",
      "24 - G\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cat ./mutation_data/results.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
