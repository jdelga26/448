{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replicating Research from Spring\n",
    "\n",
    "by Joshua Delgadillo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Update 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working on:\n",
    " 1. How to Jupyter Notebooks\n",
    " 2. Relevant Githubs\n",
    " 3. New (but similiar??) data\n",
    " 4. The Alternative Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relevant GitHubs\n",
    "\n",
    "Analysis using k-mer composition\n",
    "https://anderson-github-classroom.github.io/csc-448-project/eagranof/\n",
    "\n",
    "Even more analysis using k-mer composition\n",
    "https://anderson-github-classroom.github.io/csc-448-project/skurdogh/ \n",
    "\n",
    "Vitulgin Experimentation\n",
    "https://anderson-github-classroom.github.io/csc-448-project/cilg/\n",
    "\n",
    "The Levenshtein distance experiment\n",
    "https://anderson-github-classroom.github.io/csc-448-project/awengel/ \n",
    "\n",
    "Mutation Rate Comparison and Spike Proteins\n",
    "https://anderson-github-classroom.github.io/csc-448-project/pamidi/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Sample Data\n",
    "\n",
    "The [NCBI Nucleotide Database] was used to get data last time: \"This database provides multiple SARS-Cov-2 sequences, but in an effort to focus our analysis, we select an arbitrarily random subset of sequences to analyze\". I have a simple thought: we choose another arbitrarily random subset of sequences to analyze, which will put us at arbitrary<sup>2</sup> (aka where you want to be)\n",
    "\n",
    "According to the [report from Spring], 677 sequences were used. Therefore, we should use 678 to literally 1-up them. We can compare our dataset to theirs to ensure everything looks right.\n",
    "\n",
    "[NCBI Nucleotide Database]: https://www.ncbi.nlm.nih.gov/nuccore\n",
    "[report from Spring]: https://nbviewer.jupyter.org/github/anderson-github-classroom/csc-448-project/blob/master/students/enewcome/supplemental-table/table.ipynb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Alternative Algorithm\n",
    "\n",
    "Needleman-Wunsch Algorithm or the Smith-Waterman Algorithm can be used to compare the similiarity of two viruses. The former was used in the Spring, so we will use the Smith-Waterman Algorithm.\n",
    "\n",
    "From what I can tell (and I'm not smart...so grains of salt), NWA fins the optimal global alignment and SWA find the best local alignment, which means: \"something\". I need to look back at my sequence alignment notes, but here are my current thoughts: If we run the SWA algorithm and the local alignment is enormous, then the strands of RNA are very similiar.\n",
    "\n",
    "Some pseduo code:\n",
    "\n",
    "~~~\n",
    "\n",
    "Given: String s1 with length m , String s2 with length n\n",
    "\n",
    "    // initialize matrix, M\n",
    "    \n",
    "    // score cells in matrix\n",
    "    for i=1 to m\n",
    "        for j=1 to n\n",
    "        \n",
    "            // initialization: max is 0\n",
    "            max = 0 \n",
    "            \n",
    "            // first comparison: west cell (deletion)\n",
    "            score = M[i][j-1] + gapScore\n",
    "            if( score > max )\n",
    "                max = score\n",
    "            \n",
    "            // second comparison: north cell (insertion)\n",
    "            score = M[i-1][j] + gapScore\n",
    "            if( score > max )\n",
    "                max = score\n",
    "            \n",
    "            // last comparison: north-west cell (alignment)\n",
    "            base1 = s1[j-1]\n",
    "            base2 = s2[i-1]\n",
    "            \n",
    "            if( base1 == base2 )              // match\n",
    "                alignmentScore = matchScore\n",
    "            else                              // mismatch\n",
    "                alignmentScore = mismatchScore\n",
    "            \n",
    "            score = M[i-1][j-1] + alignmentScore\n",
    "            if( score > max )\n",
    "                max = score\n",
    "            \n",
    "            // finished all comparisons\n",
    "            M[i][j] = max\n",
    "    \n",
    "    // return completed matrix\n",
    "    return M\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stray Thoughts\n",
    "\n",
    "1. There were doubts about Virulign, can't we just use Blast?\n",
    "2. Need to verify my beliefs with bio.\n",
    "3. Shoudl we use only the most recent data.\n",
    "4. SWA is hopefully mostly done after our lab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Update 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feedback\n",
    "\n",
    "Professor Anderson asked us to consider if we should or shouldn't implement the algorithm by hand. The primary benefit would be our familiarization with the code and control over parameters, but we give up precious time. \n",
    "\n",
    "We decided to try using BLAST after all, but <b>is it actually what we need?</b> Names can be very misleading."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proving we can use BLAST\n",
    "\n",
    "Proof by obvious: \n",
    "~~~\n",
    "\n",
    "lemma 1: Smith-Waterman is a \"local aligment\" algorithm.\n",
    "\n",
    "B.L.A.S.T. stands for basic \"local alignment\" search tool.\n",
    "\n",
    "Done.\n",
    "~~~\n",
    "\n",
    "From the [BLAST website]: \"The Basic Local Alignment Search Tool (BLAST) finds regions of local similarity between sequences. The program compares nucleotide or protein sequences to sequence databases and calculates the statistical significance of matches.\"\n",
    "\n",
    "BLAST uses a faster version of Smith-Waterman. A heuristic is used to eliminate sequences that are not likely to be a good local alignment. The shortcut was necessary because the algorithm is too slow when ran with large datasets. source: [The NCBI Handbook]\n",
    "\n",
    "[BLAST website]: https://blast.ncbi.nlm.nih.gov/Blast.cgi\n",
    "[The NCBI Handbook]: https://www.unmc.edu/bsbc/docs/NCBI_blast.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Data\n",
    "\n",
    "I pulled (at the time) recent data in the [NCBI] database. There are strands of SARS-CoV-1, SARS-CoV-2, and MERS-CoV. I unironically-ironically tried 678 sequences and realized I had just read about how the alogrithm struggles with large datasets. I decided to scale it back a lot becuase logic supersedes sarcasm. The function \"print_fasta\" does exactly what you think it does. \n",
    "\n",
    "[NCBI]: https://www.ncbi.nlm.nih.gov/labs/virus/vssi/#/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "import pandas as pd \n",
    "  \n",
    "def print_fasta(virus_name, file_name):\n",
    "    # initialize list of lists \n",
    "    data = []\n",
    "\n",
    "    fasta_sequences = SeqIO.parse(open(file_name),'fasta')\n",
    "    with open(file_name) as out_file:\n",
    "        for fasta in fasta_sequences:\n",
    "            name, sequence = fasta.id, str(fasta.seq)\n",
    "            data.append([name, sequence])\n",
    "\n",
    "    # Create the pandas DataFrame \n",
    "    df = pd.DataFrame(data, columns = [virus_name, 'sequence']) \n",
    "\n",
    "    # print dataframe. \n",
    "    print(df) \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     SARS-CoV-1                                           sequence\n",
      "0    QOQ06483.1  MESLVPGFNEKTHVQLSLPVLQVRDVLVRGFGDSVEEVLSEARQHL...\n",
      "1    QOQ06484.1  MESLVPGFNEKTHVQLSLPVLQVRDVLVRGFGDSVEEVLSEARQHL...\n",
      "2    QOQ06485.1  MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...\n",
      "3    QOQ06486.1  MDLFMRIFTIGTVTLKQGEIKDATPSDFVRATATIPIQASLPFGWL...\n",
      "4    QOQ06487.1  MYSFVSEETGTLIVNSVLLFLAFVVFLLVTLAILTALRLCAYCCNI...\n",
      "..          ...                                                ...\n",
      "595  QOQ07078.1  MKIILFLALITLATCELYHYQECVRGTTVLLKEPCSSGTYEGNSPF...\n",
      "596  QOQ07079.1         MIELSLIDFYLCLAFLLFLVLIMLIIFWFSLELQDHNETCHA\n",
      "597  QOQ07080.1  MKFLVFLGIITTVAAFHQECSLQSCTQHQPYVVDDPCPIHFYSKWY...\n",
      "598  QOQ07081.1  MSDNGPQNQRNAPRITFGGPSDSTGSNQNGERSGARSKQRRPQGLP...\n",
      "599  QOQ07082.1             MGYINVFAFPFTIYSLLLCRMNSRNYIAQVDVVNFNLT\n",
      "\n",
      "[600 rows x 2 columns]\n",
      "\n",
      "     SARS-CoV-2                                           sequence\n",
      "0    QOP98696.1  MESLVPGFNEKTHVQLSLPVLQVRDVLVRGFGDSVEEVLSEARQHL...\n",
      "1    QOP98697.1  MESLVPGFNEKTHVQLSLPVLQVRDVLVRGFGDSVEEVLSEARQHL...\n",
      "2    QOP98698.1  MFVFLVLLPLVSSQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSS...\n",
      "3    QOP98699.1  MDLFMRIFTIGTVTLKQGEIKDATPSDFVRATATIPIQASLPFGWL...\n",
      "4    QOP98700.1  MYSFVSEETGTLIVNSVLLFLAFVVFLLVTLAILTALRLCAYCCNI...\n",
      "..          ...                                                ...\n",
      "595  QOP99291.1  MKIILFLALITLATCELYHYQECVRGTTVLLKEPCSSGTYEGNSPF...\n",
      "596  QOP99292.1        MIELSLIDFYLCFLAFLLFLVLIMLIIFWFSLELQDHNETCHA\n",
      "597  QOP99293.1  MKFLVFLGIITTVAAFHQECSLQSCTQHQPYVVDDPCPIHFYSKWY...\n",
      "598  QOP99294.1  MSDNGPQNQRNAPRITFGGPSDSTGSNQNGERSGARSKQRRPQGLP...\n",
      "599  QOP99295.1             MGYINVFAFPFTIYSLLLCRMNSRNYIAQVDVVNFNLT\n",
      "\n",
      "[600 rows x 2 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_fasta(\"SARS-CoV-1\", \"SARS-CoV-1.fasta\")\n",
    "print()\n",
    "print_fasta(\"SARS-CoV-2\", \"SARS-CoV-2.fasta\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLASTing Seqeunces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to create a blast database for our 3 datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Building a new DB, current time: 10/26/2020 18:38:22\n",
      "New DB name:   /home/jupyter-jdelga26/448/SARS-CoV-1.fasta\n",
      "New DB title:  SARS-CoV-1.fasta\n",
      "Sequence type: Protein\n",
      "Deleted existing Protein BLAST database named /home/jupyter-jdelga26/448/SARS-CoV-1.fasta\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 600 sequences in 0.0198441 seconds.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Building a new DB, current time: 10/26/2020 18:38:22\n",
      "New DB name:   /home/jupyter-jdelga26/448/SARS-CoV-2.fasta\n",
      "New DB title:  SARS-CoV-2.fasta\n",
      "Sequence type: Protein\n",
      "Deleted existing Protein BLAST database named /home/jupyter-jdelga26/448/SARS-CoV-2.fasta\n",
      "Keep MBits: T\n",
      "Maximum file size: 1000000000B\n",
      "Adding sequences from FASTA; added 600 sequences in 0.0198081 seconds.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "/usr/local/ncbi-blast-2.10.1+/bin/makeblastdb -in SARS-CoV-1.fasta -dbtype prot\n",
    "/usr/local/ncbi-blast-2.10.1+/bin/makeblastdb -in SARS-CoV-2.fasta -dbtype prot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We did it! Where are our diplomas? Next, we run blast on every pair:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "/usr/local/ncbi-blast-2.10.1+/bin/blastp -query SARS-CoV-1.fasta -db SARS-CoV-2.fasta -evalue 1e-6 -num_threads 16 -out blast.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Lambda      K        H        a         alpha\r\n",
      "   0.335    0.145    0.443    0.792     4.96 \r\n",
      "\r\n",
      "Gapped\r\n",
      "Lambda      K        H        a         alpha    sigma\r\n",
      "   0.267   0.0410    0.140     1.90     42.6     43.6 \r\n",
      "\r\n",
      "Effective search space used: 17487350\r\n",
      "\r\n",
      "\r\n",
      "  Database: SARS-CoV-2.fasta\r\n",
      "    Posted date:  Oct 26, 2020  6:38 PM\r\n",
      "  Number of letters in database: 707,294\r\n",
      "  Number of sequences in database:  600\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "Matrix: BLOSUM62\r\n",
      "Gap Penalties: Existence: 11, Extension: 1\r\n",
      "Neighboring words threshold: 11\r\n",
      "Window for multiple hits: 40\r\n"
     ]
    }
   ],
   "source": [
    "!tail -22 blast.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
